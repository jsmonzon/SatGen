{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "    \n",
    "import sys \n",
    "sys.path.insert(0, '../../src/')\n",
    "\n",
    "from astropy.table import Table\n",
    "import os\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "import corner\n",
    "import mc3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative(lgMs_1D):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        Ms (numpy): 1D mass array\n",
    "        mass_bins (numpy): mass bins\n",
    "\n",
    "    Returns:\n",
    "        CSMF (numpy): counts in each bin\n",
    "    \"\"\"\n",
    "\n",
    "    mass_bins = np.linspace(4,11,45)\n",
    "\n",
    "    N = np.histogram(lgMs_1D, bins=mass_bins)[0]\n",
    "    Nsub = np.sum(N)\n",
    "    stat = Nsub-np.cumsum(N) \n",
    "    return np.insert(stat, 0, Nsub) #to add the missing index\n",
    "\n",
    "def SHMR(lgMh_2D, alpha=1.85, delta=0.2, sigma=0.3):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns: the log stellar mass array with an added dimension corresponding to the random samples\n",
    "    \"\"\"\n",
    "\n",
    "    M_star_a = 10 # these are the anchor points\n",
    "    M_halo_a = 11.67\n",
    "\n",
    "    #print(\"not normalizing for the upscatter and assuming a 2D input array\")\n",
    "    lgMs_2D = alpha*(lgMh_2D-M_halo_a) - delta*(lgMh_2D-M_halo_a)**2 + M_star_a\n",
    "    scatter = np.random.normal(loc=0, scale=sigma, size=(lgMs_2D.shape))\n",
    "    return lgMs_2D + scatter\n",
    "\n",
    "def MODEL(theta):\n",
    "    \n",
    "    alpha, delta, sigma = theta\n",
    "\n",
    "    data = np.load(\"../../../data/3000_12_8/truth_lgMh.npy\")\n",
    "    lgMs_2D = SHMR(data, alpha, delta, sigma) # will be a 3D array if sigma is non zero\n",
    "    \n",
    "    counts = np.apply_along_axis(cumulative, 1, lgMs_2D)\n",
    "    quant = np.percentile(counts, np.array([5, 50, 95]), axis=0, method=\"closest_observation\") # median and scatter\n",
    "\n",
    "    S1 = quant[2, 16] - quant[0, 16] #16, 22, 28 corresponds to 6.5, 7, 7.5 Msol\n",
    "    S2 = quant[2, 22] - quant[0, 22]\n",
    "    S3 = quant[2, 28] - quant[0, 28]\n",
    "    N1 = quant[1, 16]\n",
    "    N2 = quant[1, 22]\n",
    "    N3 = quant[1, 28]\n",
    "\n",
    "    model = np.array([N1, N2, N3, S1, S2, S3])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  6,  1, 13,  7,  4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL([1.2, 0.3, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "# Preamble (create a synthetic dataset, in a real scenario you would\n",
    "# get your dataset from your own data analysis pipeline):\n",
    "\n",
    "data = np.array([7, 2, 1, 9, 5, 2,])\n",
    "uncert = np.array([0.372678,  0.45825757, 0.1,  0.74535599, 0.59721576, 0.48989795])\n",
    "# ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "# Define the modeling function as a callable:\n",
    "func = MODEL\n",
    "\n",
    "# List of additional arguments of func (if necessary):\n",
    "# Array of initial-guess values of fitting parameters:\n",
    "params = np.array([1, 1, 1])\n",
    "# Lower and upper boundaries for the MCMC exploration:\n",
    "pmin = np.array([1, -0.3, 0])\n",
    "pmax = np.array([ 3,  1.2,  2.5])\n",
    "# Parameters' stepping behavior:\n",
    "pstep = np.array([0.1, 0.1, 0.1])\n",
    "\n",
    "# Parameter prior probability distributions:\n",
    "prior    = np.array([ 0.0, 0.0, 0.0])\n",
    "priorlow = np.array([ 0.0, 0.0, 0.0])\n",
    "priorup  = np.array([ 0.0, 0.0, 0.0])\n",
    "\n",
    "# Parameter names:\n",
    "pnames = ['alpha', 'delta', 'sigma']\n",
    "texnames = [r'$\\alpha$', r'$\\delta$', r'$\\sigma$']\n",
    "\n",
    "# Sampler algorithm, choose from: 'snooker', 'demc' or 'mrw'.\n",
    "sampler = 'snooker'\n",
    "\n",
    "# MCMC setup:\n",
    "nsamples =  1e4\n",
    "burnin   =  100\n",
    "nchains  =  14\n",
    "ncpu     =  7\n",
    "thinning =  1\n",
    "\n",
    "# MCMC initial draw, choose from: 'normal' or 'uniform'\n",
    "kickoff = 'normal'\n",
    "# DEMC snooker pre-MCMC sample size:\n",
    "hsize = 10\n",
    "\n",
    "# Optimization before MCMC, choose from: 'lm' or 'trf':\n",
    "leastsq = 'lm'\n",
    "chisqscale = False\n",
    "\n",
    "# MCMC Convergence:\n",
    "grtest = True\n",
    "grbreak = 1.01\n",
    "grnmin = 0.3\n",
    "\n",
    "# Logging:\n",
    "log = 'MCMC_run.log'\n",
    "\n",
    "# File outputs:\n",
    "savefile = 'MCMC_run.npz'\n",
    "plots = True\n",
    "theme = 'indigo'\n",
    "statistics = 'med_central'\n",
    "rms = True\n",
    "\n",
    "# Carter & Winn (2009) Wavelet-likelihood method:\n",
    "wlike = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "  Multi-core Markov-chain Monte Carlo (mc3).\n",
      "  Version 3.1.2.\n",
      "  Copyright (c) 2015-2023 Patricio Cubillos and collaborators.\n",
      "  mc3 is open-source software under the MIT license (see LICENSE).\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "Least-squares best-fitting parameters:\n",
      "  [1 1 1]\n",
      "\n",
      "Yippee Ki Yay Monte Carlo!\n",
      "Start MCMC chains  (Wed Apr 19 15:38:48 2023)\n",
      "\n",
      "[:         ]  10.0% completed  (Wed Apr 19 15:38:49 2023)\n",
      "Out-of-bound Trials:\n",
      "[ 0  9 18]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "\n",
      "[::        ]  20.0% completed  (Wed Apr 19 15:38:50 2023)\n",
      "Out-of-bound Trials:\n",
      "[ 0 14 26]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "Gelman-Rubin statistics for free parameters:\n",
      "[       nan 1.20094801 1.12897703]\n",
      "\n",
      "[:::       ]  30.0% completed  (Wed Apr 19 15:38:51 2023)\n",
      "Out-of-bound Trials:\n",
      "[ 0 15 30]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "Gelman-Rubin statistics for free parameters:\n",
      "[       nan 1.07138856 1.15335081]\n",
      "\n",
      "[::::      ]  40.0% completed  (Wed Apr 19 15:38:51 2023)\n",
      "Out-of-bound Trials:\n",
      "[ 0 16 47]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "Gelman-Rubin statistics for free parameters:\n",
      "[       nan 1.04261912 1.08547502]\n",
      "\n",
      "[:::::     ]  50.0% completed  (Wed Apr 19 15:38:52 2023)\n",
      "Out-of-bound Trials:\n",
      "[ 0 17 65]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "Gelman-Rubin statistics for free parameters:\n",
      "[       nan 1.04178631 1.03407134]\n",
      "\n",
      "[::::::    ]  60.0% completed  (Wed Apr 19 15:38:53 2023)\n",
      "Out-of-bound Trials:\n",
      "[ 0 17 88]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "Gelman-Rubin statistics for free parameters:\n",
      "[       nan 1.02913181 1.01915141]\n",
      "\n",
      "[:::::::   ]  70.0% completed  (Wed Apr 19 15:38:54 2023)\n",
      "Out-of-bound Trials:\n",
      "[  0  20 112]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "Gelman-Rubin statistics for free parameters:\n",
      "[       nan 1.03419521 1.01929844]\n",
      "\n",
      "[::::::::  ]  80.0% completed  (Wed Apr 19 15:38:55 2023)\n",
      "Out-of-bound Trials:\n",
      "[  0  23 141]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "Gelman-Rubin statistics for free parameters:\n",
      "[       nan 1.05601831 1.02278056]\n",
      "\n",
      "[::::::::: ]  90.0% completed  (Wed Apr 19 15:38:55 2023)\n",
      "Out-of-bound Trials:\n",
      "[  0  33 171]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "Gelman-Rubin statistics for free parameters:\n",
      "[       nan 1.0471094  1.02441843]\n",
      "\n",
      "[::::::::::] 100.0% completed  (Wed Apr 19 15:38:56 2023)\n",
      "Out-of-bound Trials:\n",
      "[  0  39 205]\n",
      "Best Parameters: (chisq=0.0000)\n",
      "[1. 1. 1.]\n",
      "Gelman-Rubin statistics for free parameters:\n",
      "[       nan 1.0397751  1.02187123]\n",
      "\n",
      "MCMC Summary:\n",
      "-------------\n",
      "  Number of evaluated samples:        10010\n",
      "  Number of parallel chains:             14\n",
      "  Average iterations per chain:         715\n",
      "  Burned-in iterations per chain:       100\n",
      "  Thinning factor:                        1\n",
      "  MCMC sample size (thinned, burned):  8610\n",
      "  Acceptance rate:   92.31%\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Run the MCMC:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output \u001b[39m=\u001b[39m mc3\u001b[39m.\u001b[39;49msample(\n\u001b[1;32m      3\u001b[0m     data\u001b[39m=\u001b[39;49mdata, uncert\u001b[39m=\u001b[39;49muncert, func\u001b[39m=\u001b[39;49mfunc, params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m      4\u001b[0m     pmin\u001b[39m=\u001b[39;49mpmin, pmax\u001b[39m=\u001b[39;49mpmax, pstep\u001b[39m=\u001b[39;49mpstep,\n\u001b[1;32m      5\u001b[0m     pnames\u001b[39m=\u001b[39;49mpnames, texnames\u001b[39m=\u001b[39;49mtexnames,\n\u001b[1;32m      6\u001b[0m     prior\u001b[39m=\u001b[39;49mprior, priorlow\u001b[39m=\u001b[39;49mpriorlow, priorup\u001b[39m=\u001b[39;49mpriorup,\n\u001b[1;32m      7\u001b[0m     sampler\u001b[39m=\u001b[39;49msampler, nsamples\u001b[39m=\u001b[39;49mnsamples,  nchains\u001b[39m=\u001b[39;49mnchains,\n\u001b[1;32m      8\u001b[0m     ncpu\u001b[39m=\u001b[39;49mncpu, burnin\u001b[39m=\u001b[39;49mburnin, thinning\u001b[39m=\u001b[39;49mthinning,\n\u001b[1;32m      9\u001b[0m     leastsq\u001b[39m=\u001b[39;49mleastsq, chisqscale\u001b[39m=\u001b[39;49mchisqscale,\n\u001b[1;32m     10\u001b[0m     grtest\u001b[39m=\u001b[39;49mgrtest, grbreak\u001b[39m=\u001b[39;49mgrbreak, grnmin\u001b[39m=\u001b[39;49mgrnmin,\n\u001b[1;32m     11\u001b[0m     hsize\u001b[39m=\u001b[39;49mhsize, kickoff\u001b[39m=\u001b[39;49mkickoff,\n\u001b[1;32m     12\u001b[0m     wlike\u001b[39m=\u001b[39;49mwlike, log\u001b[39m=\u001b[39;49mlog,\n\u001b[1;32m     13\u001b[0m     plots\u001b[39m=\u001b[39;49mplots, theme\u001b[39m=\u001b[39;49mtheme, statistics\u001b[39m=\u001b[39;49mstatistics,\n\u001b[1;32m     14\u001b[0m     savefile\u001b[39m=\u001b[39;49msavefile, rms\u001b[39m=\u001b[39;49mrms,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/subhalos/lib/python3.10/site-packages/mc3/sampler_driver.py:509\u001b[0m, in \u001b[0;36msample\u001b[0;34m(data, uncert, func, params, indparams, indparams_dict, pmin, pmax, pstep, prior, priorlow, priorup, sampler, ncpu, leastsq, chisqscale, nchains, nsamples, burnin, thinning, grtest, grbreak, grnmin, wlike, fgamma, fepsilon, hsize, kickoff, plots, theme, statistics, ioff, showbp, savefile, resume, rms, log, pnames, texnames, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m posterior, zchain, zmask \u001b[39m=\u001b[39m mu\u001b[39m.\u001b[39mburn(\n\u001b[1;32m    506\u001b[0m     Z\u001b[39m=\u001b[39moutput[\u001b[39m'\u001b[39m\u001b[39mposterior\u001b[39m\u001b[39m'\u001b[39m], zchain\u001b[39m=\u001b[39moutput[\u001b[39m'\u001b[39m\u001b[39mzchain\u001b[39m\u001b[39m'\u001b[39m], burnin\u001b[39m=\u001b[39moutput[\u001b[39m'\u001b[39m\u001b[39mburnin\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    508\u001b[0m bestp \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mbestp\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 509\u001b[0m post \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39;49mPosterior(\n\u001b[1;32m    510\u001b[0m     posterior, pnames\u001b[39m=\u001b[39;49mtexnames[ifree], theme\u001b[39m=\u001b[39;49mtheme,\n\u001b[1;32m    511\u001b[0m     bestp\u001b[39m=\u001b[39;49mbestp[ifree], statistics\u001b[39m=\u001b[39;49mstatistics,\n\u001b[1;32m    512\u001b[0m )\n\u001b[1;32m    513\u001b[0m \u001b[39mprint\u001b[39m(post\u001b[39m.\u001b[39mstatistics)\n\u001b[1;32m    514\u001b[0m \u001b[39m# Let Posterior to turn the theme into a Theme() object:\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/subhalos/lib/python3.10/site-packages/mc3/plots/posterior.py:1066\u001b[0m, in \u001b[0;36mPosterior.__init__\u001b[0;34m(self, posterior, pnames, bestp, ranges, statistics, quantile, sample_size, theme, orientation, show_texts, show_estimates, show_colorbar, seed)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhpd_min \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnpars)]\n\u001b[1;32m   1065\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnpars):\n\u001b[0;32m-> 1066\u001b[0m     pdf, xpdf, hpd \u001b[39m=\u001b[39m ms\u001b[39m.\u001b[39;49mcred_region(\n\u001b[1;32m   1067\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mposterior[:,i], quantile\u001b[39m=\u001b[39;49mquantile,\n\u001b[1;32m   1068\u001b[0m     )\n\u001b[1;32m   1069\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpdf[i] \u001b[39m=\u001b[39m pdf\n\u001b[1;32m   1070\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxpdf[i] \u001b[39m=\u001b[39m xpdf\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/subhalos/lib/python3.10/site-packages/mc3/stats/stats.py:440\u001b[0m, in \u001b[0;36mcred_region\u001b[0;34m(posterior, quantile, pdf, xpdf)\u001b[0m\n\u001b[1;32m    438\u001b[0m thinning \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mamax([\u001b[39m1\u001b[39m, \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39msize(posterior)\u001b[39m/\u001b[39m\u001b[39m120000\u001b[39m)])\n\u001b[1;32m    439\u001b[0m \u001b[39m# Compute the posterior's PDF:\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m kernel \u001b[39m=\u001b[39m ss\u001b[39m.\u001b[39;49mgaussian_kde(posterior[::thinning])\n\u001b[1;32m    441\u001b[0m \u001b[39m# Remove outliers:\u001b[39;00m\n\u001b[1;32m    442\u001b[0m mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(posterior)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/subhalos/lib/python3.10/site-packages/scipy/stats/_kde.py:207\u001b[0m, in \u001b[0;36mgaussian_kde.__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`weights` input should be of length n\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_neff \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_bandwidth(bw_method\u001b[39m=\u001b[39;49mbw_method)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/subhalos/lib/python3.10/site-packages/scipy/stats/_kde.py:555\u001b[0m, in \u001b[0;36mgaussian_kde.set_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    551\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m`bw_method` should be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mscott\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msilverman\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, a scalar \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m    552\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mor a callable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 555\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_covariance()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/subhalos/lib/python3.10/site-packages/scipy/stats/_kde.py:567\u001b[0m, in \u001b[0;36mgaussian_kde._compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_data_inv_cov\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_covariance \u001b[39m=\u001b[39m atleast_2d(cov(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, rowvar\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    565\u001b[0m                                        bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    566\u001b[0m                                        aweights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights))\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_inv_cov \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49minv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_covariance)\n\u001b[1;32m    569\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovariance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_covariance \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactor\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m    570\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minv_cov \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_inv_cov \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactor\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/subhalos/lib/python3.10/site-packages/scipy/linalg/_basic.py:956\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    954\u001b[0m     inv_a, info \u001b[39m=\u001b[39m getri(lu, piv, lwork\u001b[39m=\u001b[39mlwork, overwrite_lu\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 956\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39msingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    957\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39millegal value in \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-th argument of internal \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    959\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mgetrf|getri\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m \u001b[39m-\u001b[39minfo)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: singular matrix"
     ]
    }
   ],
   "source": [
    "# Run the MCMC:\n",
    "output = mc3.sample(\n",
    "    data=data, uncert=uncert, func=func, params=params,\n",
    "    pmin=pmin, pmax=pmax, pstep=pstep,\n",
    "    pnames=pnames, texnames=texnames,\n",
    "    prior=prior, priorlow=priorlow, priorup=priorup,\n",
    "    sampler=sampler, nsamples=nsamples,  nchains=nchains,\n",
    "    ncpu=ncpu, burnin=burnin, thinning=thinning,\n",
    "    leastsq=leastsq, chisqscale=chisqscale,\n",
    "    grtest=grtest, grbreak=grbreak, grnmin=grnmin,\n",
    "    hsize=hsize, kickoff=kickoff,\n",
    "    wlike=wlike, log=log,\n",
    "    plots=plots, theme=theme, statistics=statistics,\n",
    "    savefile=savefile, rms=rms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = np.load(\"MCMC_run.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(25.04495504)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run[\"acceptance_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subhalos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
