{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/jsmonzon/Research/SatGen/mcmc/src/')\n",
    "import jsm_halopull\n",
    "import jsm_SHMR\n",
    "import jsm_mcmc\n",
    "import jsm_stats\n",
    "import jsm_models\n",
    "import seaborn as sns\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('../paper/paper.mplstyle')\n",
    "double_textwidth = 7.0 #inches\n",
    "single_textwidth = 3.5 #inches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calling in 10k merger tree realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def lnL_PNsat(data, model):\n",
    "    lnL = np.sum(np.log(model.PNsat[data.Nsat_perhost]))\n",
    "    if np.isinf(lnL):\n",
    "        #print(\"index error in Pnsat\")\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return lnL\n",
    "\n",
    "def lnL_KS_max(data, model):\n",
    "    try:\n",
    "        clean_max_split = list(map(model.max_split.__getitem__, data.model_mask)) # this might yield an index error!\n",
    "        p_vals = np.array(list(map(lambda x, y: ks_2samp(x, y)[1], data.clean_max_split, clean_max_split)))\n",
    "        return np.sum(np.log(p_vals))\n",
    "    except IndexError:\n",
    "        #print(\"this model is not preferable!\")\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def measure_lnLvar_D(fid_theta=[10.5, 2.0, 0,0, 0.0, 0.2, 0.0], min_mass=6.5):\n",
    "\n",
    "#     lnLs = []\n",
    "        \n",
    "#     for SAGA_ind in range(100):\n",
    "#         class_i = jsm_models.SAMPLE_SAGA_MODELS(fid_theta, meta_path=\"../../../data/MW-analog/meta_data_psi4/\", extra_path=\"../../../data/MW-analog/meta_data_psi3/\", SAGA_ind=SAGA_ind, verbose=False)\n",
    "#         Dstat_i = jsm_stats.SatStats_D(class_i.lgMs_data, min_mass, max_N=500)\n",
    "#         Mstat_i = jsm_stats.SatStats_M(class_i.lgMs_model, min_mass, max_N=500)\n",
    "\n",
    "#         lnL_i = lnL_PNsat(Dstat_i, Mstat_i) + lnL_KS_max(Dstat_i, Mstat_i)\n",
    "#         lnLs.append(lnL_i)\n",
    "\n",
    "#     lnLs  = np.array(lnLs)\n",
    "#     lnLs_clean = lnLs[~np.isinf(lnLs)]\n",
    "#     return lnLs_clean.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dvar_S0 = measure_lnL_dvar(\"../../../data/MW-analog/meta_data_psi3/\") #7.072\n",
    "#dvar_S15 = measure_lnL_dvar(\"../../../data/cross_host/lognorm_015_psi3/\") #8.229\n",
    "#dvar_S30 = measure_lnL_dvar(\"../../../data/cross_host/lognorm_030_psi3/\") #12.350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now the variance in the models with respect to Nhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_lnLvar_M(Nhost_per_model, SAGA_ind, fid_theta=[10.5, 2.0, 0,0, 0.0, 0.2, 0.0], min_mass=6.5):\n",
    "    \n",
    "    #print(\"selecting the\", SAGA_ind, \"SAGA index\")    \n",
    "    class_i = jsm_models.SAMPLE_SAGA_MODELS(fid_theta, meta_path=\"../../../data/MW-analog/meta_data_psi4/\", extra_path=\"../../../data/MW-analog/meta_data_psi3/\", SAGA_ind=SAGA_ind, verbose=False)\n",
    "    Dstat_i = jsm_stats.SatStats_D(class_i.lgMs_data, min_mass, max_N=500)\n",
    "\n",
    "    Nhost_extra = class_i.lgMs_model.shape[0] % Nhost_per_model\n",
    "    if Nhost_extra == 0:\n",
    "        N_models = int(class_i.lgMs_model.shape[0] / Nhost_per_model)\n",
    "        class_i.lgMs_model = class_i.lgMs_model.reshape([N_models, Nhost_per_model, class_i.lgMs_model.shape[1]])\n",
    "    else:\n",
    "        class_i.lgMs_model = np.delete(class_i.lgMs_model, np.arange(Nhost_extra), axis=0)\n",
    "        N_models = int(class_i.lgMs_model.shape[0] / Nhost_per_model)\n",
    "        class_i.lgMs_model = class_i.lgMs_model.reshape([N_models, Nhost_per_model,  class_i.lgMs_model.shape[1]])\n",
    "\n",
    "    # print(\"When Nhost = \", Nhost_per_model, \",there are\", Nhost_extra, \"extra trees. That leaves\", N_models, \"model realizations\")\n",
    "    # print(class_i.lgMs_model.shape)\n",
    "\n",
    "    lnLs = []\n",
    "    for model in class_i.lgMs_model:\n",
    "        Mstat_i = jsm_stats.SatStats_M(model, min_mass, max_N=500)\n",
    "        lnL_i = lnL_PNsat(Dstat_i, Mstat_i) + lnL_KS_max(Dstat_i, Mstat_i)\n",
    "        lnLs.append(lnL_i)\n",
    "\n",
    "    lnLs = np.array(lnLs)\n",
    "    inf_mask = np.isinf(lnLs)\n",
    "    Ndrops = np.sum(inf_mask)/lnLs.shape[0]\n",
    "    lnLs_clean = lnLs[~inf_mask]\n",
    "    return lnLs_clean.std(ddof=1), Ndrops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhost = np.logspace(1.1,3, 25).astype(int)\n",
    "\n",
    "# Nsaga = 100\n",
    "\n",
    "# var_mat = np.full((Nsaga, Nhost.shape[0]), np.nan)\n",
    "# drop_mat = np.full((Nsaga, Nhost.shape[0]), np.nan)\n",
    "\n",
    "# for i,index in enumerate(range(Nsaga)):\n",
    "#     for j,Nmod in enumerate(Nhost):\n",
    "#         var_ij, drop_ij = measure_lnLvar_M(Nhost_per_model=Nmod, SAGA_ind=index)\n",
    "#         var_mat[i,j] = var_ij\n",
    "#         drop_mat[i,j] = drop_ij\n",
    "\n",
    "# np.save(\"../../mcmc/inference_tests/convergence/data_saves/drop_S0.npy\", drop_mat)\n",
    "# np.save(\"../../mcmc/inference_tests/convergence/data_saves/var_S0.npy\", var_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(2, 1, sharex=True, sharey=False, figsize=(double_textwidth, double_textwidth), gridspec_kw={'height_ratios': [3, 1]})\n",
    "# axes[0].axhline(dvar_S0, ls=\"--\", color=\"green\", label=\"$\\sigma_{\\\\vec{SS}} = \\sqrt{ \\sigma_{\\\\vec{D}}^2 + \\sigma_{4}^2} $\")\n",
    "# axes[0].plot(np.log10(Nhost), np.nanmedian(var_mat, axis=0), color=\"k\", label=\"$< \\sigma_{\\\\vec{M}} >$\")\n",
    "\n",
    "# axes[1].scatter(np.log10(Nhost),1-np.median(drop_mat, axis=0), color=\"k\", marker=\"+\")\n",
    "# axes[1].set_xlabel(\"$\\log \\hat{N}_{\\mathrm{host}}$\", fontsize=15)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# #plt.savefig(\"../../../paper_1/figures/aux/convergence.pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subhalos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
